{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b7b380a-40eb-4d99-988d-89f0d3b9202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8612ad63-f8b4-4959-a4cd-beae176d4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting hyperparameters\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "train_split = 0.9\n",
    "test_split = 1 - train_split\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "320ad23c-3df1-4f01-ba30-7dd7404aea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for i,s in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efd106cd-015c-4947-99c3-e82e3e422b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(train_split*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "834b430f-8f3e-4546-9bdd-632df2c12c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding \n",
    "    PE(pos,2i) =sin(pos/10000^(2i/dmodel))\n",
    "    PE(pos,2i+1) =cos(pos/10000^(2i/dmodel))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        \"\"\"\n",
    "        pos: (seq_length, 1)\n",
    "        i: (1, d_model)\n",
    "        d_model: int (dimension of embedding)\n",
    "\n",
    "        return: (seq_length, d_model)\n",
    "        \"\"\"\n",
    "        power = 2*(i//2)/ torch.tensor(d_model, dtype=torch.float32)\n",
    "        return pos / (torch.pow(10000, power))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        assert len(inputs.shape) == 3\n",
    "        seq_length = inputs.shape[-2]\n",
    "        d_model = inputs.shape[-1]\n",
    "        angles = self.get_angles(\n",
    "            torch.arange(seq_length).unsqueeze(1),\n",
    "            torch.arange(d_model).unsqueeze(0),\n",
    "            d_model\n",
    "        )\n",
    "        \n",
    "        pe = torch.zeros(seq_length, d_model)\n",
    "        pe[:, 0::2] = torch.sin(angles[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(angles[:, 1::2])\n",
    "        pe.unsqueeze(0)\n",
    "        return inputs + pe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "420298df-66ea-40d2-b286-384cc9db0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Positional encoding test\n",
    "\"\"\"\n",
    "test_pe_input = torch.tensor([\n",
    "    [[1,2,3], [2,3,4]], \n",
    "    [[3,4,5], [4,5,6]]\n",
    "]) #batch_size = 2, seq_length = 2, d_model = 3\n",
    "pos1_i0 = torch.sin(torch.tensor(1/math.pow(10000,0)))\n",
    "pos1_i1 = torch.cos(torch.tensor(1/math.pow(10000,0)))\n",
    "pos1_i2 = torch.sin(torch.tensor(1/math.pow(10000,2/float(3))))\n",
    "expected_pe = torch.tensor([\n",
    "    [[0, 1, 0], [pos1_i0, pos1_i1, pos1_i2]], \n",
    "    [[0, 1, 0], [pos1_i0, pos1_i1, pos1_i2]]\n",
    "]) + test_pe_input\n",
    "assert (expected_pe == PositionalEncoding().forward(test_pe_input)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "697f72bb-7913-4d70-9231-d01e9e9d2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, input_shape):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = input_shape[-1]\n",
    "        self.d_head = self.d_model // self.n_heads\n",
    "        self.query_lin = nn.Linear(in_features = self.d_model, out_features = self.d_model)\n",
    "        self.key_lin = nn.Linear(in_features = self.d_model, out_features = self.d_model)\n",
    "        self.value_lin = nn.Linear(in_features = self.d_model, out_features = self.d_model)\n",
    "        self.final_lin = nn.Linear(in_features = self.d_model, out_features = self.d_model)\n",
    "        \n",
    "        \n",
    "    def scaled_dot_product_attention(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        softmax((QK.T)/sqrt(dk))V\n",
    "        \n",
    "        query: (batch_size, num_heads, seq_length, d_k)\n",
    "        key: (batch_size, num_heads, seq_length, d_k)\n",
    "        value: (batch_size, num_heads, seq_length, d_v)\n",
    "        mask: (batch_size, 1, 1, seq_length)\n",
    "        return: (batch_size, num_heads, seq_length, d_v)\n",
    "        \"\"\"\n",
    "        assert len(query.shape) == len(key.shape) and len(query.shape) == len(value.shape)\n",
    "        assert key.dtype == torch.float\n",
    "        \n",
    "        product = query @ (key.transpose(-1,-2))\n",
    "        \n",
    "        dk = torch.tensor(key.shape[-1], dtype = torch.float32)\n",
    "        sqrt_dk = torch.sqrt(dk)\n",
    "        scaled_product = product/sqrt_dk\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_product += mask * -1e9\n",
    "\n",
    "        softmax = torch.softmax(scaled_product, dim = -1)\n",
    "        attention = softmax @ value\n",
    "        return attention\n",
    "\n",
    "    def split_to_heads(self, inputs, batch_size):\n",
    "        \"\"\"\n",
    "        input: (batch_size, seq_length, d_model)\n",
    "        return: (batch_size, n_proj, seq_length, d_model//n_heads)\n",
    "        \"\"\"\n",
    "        proj_inputs = inputs.view(batch_size, -1, self.n_heads, self.d_head)\n",
    "        return proj_inputs.transpose(1, 2)\n",
    "\n",
    "    def concat_from_heads(self, inputs, batch_size):\n",
    "        \"\"\"\n",
    "        input: (batch_size, n_proj, seq_length, d_model//n_heads)\n",
    "        return: (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        return inputs.transpose(2,1).view(batch_size, -1, self.d_model)\n",
    "\n",
    "    def multi_head_attention(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query: (batch_size, seq_length, d_model)\n",
    "        key: (batch_size, seq_length, d_model)\n",
    "        value: (batch_size, seq_length, d_model)\n",
    "        mask: (batch_size, 1, 1, seq_length)\n",
    "        \n",
    "        return: (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        batch_size = query.shape[0]\n",
    "        queries = self.query_lin(query)\n",
    "        keys = self.key_lin(key)\n",
    "        values = self.value_lin(value)\n",
    "\n",
    "        queries = self.spli_to_heads(queries, batch_size)\n",
    "        keys = self.spli_to_heads(keys, batch_size)\n",
    "        values = self.spli_to_heads(values, batch_size)\n",
    "\n",
    "        attention = self.scaled_dot_product_attention(queries, keys, values, mask)\n",
    "\n",
    "        attention = self.concat_from_heads(attention, batch_size)\n",
    "        outputs = self.final_lin(attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a7e40-bf19-436c-8002-aed556e2afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f3c07a71-1a5e-488c-a141-bc1422da6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scaled Dot Product Attention\n",
    "\"\"\"\n",
    "test_scaled_dot_attention = torch.tensor([\n",
    "    [[1,2,3], [2,3,4]], \n",
    "    [[3,4,5], [4,5,6]]\n",
    "], dtype = torch.float32) #batch_size:2, seq_length: 2, d_model: 3\n",
    "test_mask = torch.tensor([\n",
    "    [[0, 0]],\n",
    "    [[0, 1]]\n",
    "])# (batch_size, 1, seq_length)\n",
    "test_product = torch.tensor([[[14., 20.],\n",
    "         [20., 29.]],\n",
    "        [[50., 62.],\n",
    "         [62., 77.]]], dtype = torch.float32)\n",
    "test_scaled_product = test_product/math.sqrt(3)\n",
    "test_scaled_product[1, :, 1] += -1e9 #applying mask\n",
    "expected_attention = torch.softmax(test_scaled_product, dim = -1) @ test_scaled_dot_attention\n",
    "assert (expected_attention == MultiHeadAttention(5, test_scaled_dot_attention.shape).scaled_dot_product_attention(test_scaled_dot_attention, test_scaled_dot_attention, test_scaled_dot_attention, test_mask)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0caf9ecc-42b5-4618-861f-fecf7c044f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ceaa23-64c0-4860-8a97-5051852b5b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
